{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"../DATA/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.0936 - accuracy: 0.9667 - val_loss: 0.1086 - val_accuracy: 0.9667\n",
      "Epoch 2/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.0936 - accuracy: 0.9667 - val_loss: 0.1090 - val_accuracy: 0.9667\n",
      "Epoch 3/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.0934 - accuracy: 0.9750 - val_loss: 0.1088 - val_accuracy: 0.9667\n",
      "Epoch 4/1000\n",
      "120/120 [==============================] - 0s 249us/sample - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.1088 - val_accuracy: 0.9667\n",
      "Epoch 5/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.0931 - accuracy: 0.9750 - val_loss: 0.1084 - val_accuracy: 0.9667\n",
      "Epoch 6/1000\n",
      "120/120 [==============================] - 0s 241us/sample - loss: 0.0931 - accuracy: 0.9667 - val_loss: 0.1080 - val_accuracy: 0.9667\n",
      "Epoch 7/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.1079 - val_accuracy: 0.9667\n",
      "Epoch 8/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.1078 - val_accuracy: 0.9667\n",
      "Epoch 9/1000\n",
      "120/120 [==============================] - 0s 382us/sample - loss: 0.0928 - accuracy: 0.9667 - val_loss: 0.1075 - val_accuracy: 0.9667\n",
      "Epoch 10/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.0929 - accuracy: 0.9667 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
      "Epoch 11/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.0924 - accuracy: 0.9667 - val_loss: 0.1074 - val_accuracy: 0.9667\n",
      "Epoch 12/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1078 - val_accuracy: 0.9667\n",
      "Epoch 13/1000\n",
      "120/120 [==============================] - 0s 324us/sample - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1082 - val_accuracy: 0.9667\n",
      "Epoch 14/1000\n",
      "120/120 [==============================] - 0s 316us/sample - loss: 0.0922 - accuracy: 0.9750 - val_loss: 0.1083 - val_accuracy: 0.9667\n",
      "Epoch 15/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.0921 - accuracy: 0.9750 - val_loss: 0.1082 - val_accuracy: 0.9667\n",
      "Epoch 16/1000\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.0920 - accuracy: 0.9750 - val_loss: 0.1081 - val_accuracy: 0.9667\n",
      "Epoch 17/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.1078 - val_accuracy: 0.9667\n",
      "Epoch 18/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0918 - accuracy: 0.9750 - val_loss: 0.1072 - val_accuracy: 0.9667\n",
      "Epoch 19/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0916 - accuracy: 0.9750 - val_loss: 0.1069 - val_accuracy: 0.9667\n",
      "Epoch 20/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0914 - accuracy: 0.9750 - val_loss: 0.1067 - val_accuracy: 0.9667\n",
      "Epoch 21/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0914 - accuracy: 0.9750 - val_loss: 0.1067 - val_accuracy: 0.9667\n",
      "Epoch 22/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0913 - accuracy: 0.9750 - val_loss: 0.1066 - val_accuracy: 0.9667\n",
      "Epoch 23/1000\n",
      "120/120 [==============================] - 0s 549us/sample - loss: 0.0912 - accuracy: 0.9750 - val_loss: 0.1064 - val_accuracy: 0.9667\n",
      "Epoch 24/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.1064 - val_accuracy: 0.9667\n",
      "Epoch 25/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.1063 - val_accuracy: 0.9667\n",
      "Epoch 26/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.0909 - accuracy: 0.9750 - val_loss: 0.1060 - val_accuracy: 0.9667\n",
      "Epoch 27/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0908 - accuracy: 0.9667 - val_loss: 0.1057 - val_accuracy: 0.9667\n",
      "Epoch 28/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0907 - accuracy: 0.9750 - val_loss: 0.1060 - val_accuracy: 0.9667\n",
      "Epoch 29/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0906 - accuracy: 0.9750 - val_loss: 0.1061 - val_accuracy: 0.9667\n",
      "Epoch 30/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0905 - accuracy: 0.9750 - val_loss: 0.1058 - val_accuracy: 0.9667\n",
      "Epoch 31/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.0903 - accuracy: 0.9750 - val_loss: 0.1059 - val_accuracy: 0.9667\n",
      "Epoch 32/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.0902 - accuracy: 0.9750 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
      "Epoch 33/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0901 - accuracy: 0.9750 - val_loss: 0.1055 - val_accuracy: 0.9667\n",
      "Epoch 34/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0900 - accuracy: 0.9750 - val_loss: 0.1055 - val_accuracy: 0.9667\n",
      "Epoch 35/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0899 - accuracy: 0.9750 - val_loss: 0.1052 - val_accuracy: 0.9667\n",
      "Epoch 36/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0898 - accuracy: 0.9750 - val_loss: 0.1054 - val_accuracy: 0.9667\n",
      "Epoch 37/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0897 - accuracy: 0.9750 - val_loss: 0.1052 - val_accuracy: 0.9667\n",
      "Epoch 38/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0899 - accuracy: 0.9750 - val_loss: 0.1046 - val_accuracy: 0.9667\n",
      "Epoch 39/1000\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.0894 - accuracy: 0.9667 - val_loss: 0.1046 - val_accuracy: 0.9667\n",
      "Epoch 40/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.1047 - val_accuracy: 0.9667\n",
      "Epoch 41/1000\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.0892 - accuracy: 0.9750 - val_loss: 0.1045 - val_accuracy: 0.9667\n",
      "Epoch 42/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.0893 - accuracy: 0.9750 - val_loss: 0.1048 - val_accuracy: 0.9667\n",
      "Epoch 43/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0891 - accuracy: 0.9750 - val_loss: 0.1044 - val_accuracy: 0.9667\n",
      "Epoch 44/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.0889 - accuracy: 0.9750 - val_loss: 0.1043 - val_accuracy: 0.9667\n",
      "Epoch 45/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0888 - accuracy: 0.9750 - val_loss: 0.1042 - val_accuracy: 0.9667\n",
      "Epoch 46/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0887 - accuracy: 0.9750 - val_loss: 0.1041 - val_accuracy: 0.9667\n",
      "Epoch 47/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.0887 - accuracy: 0.9750 - val_loss: 0.1040 - val_accuracy: 0.9667\n",
      "Epoch 48/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0885 - accuracy: 0.9750 - val_loss: 0.1039 - val_accuracy: 0.9667\n",
      "Epoch 49/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0885 - accuracy: 0.9750 - val_loss: 0.1041 - val_accuracy: 0.9667\n",
      "Epoch 50/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.0883 - accuracy: 0.9750 - val_loss: 0.1040 - val_accuracy: 0.9667\n",
      "Epoch 51/1000\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.0883 - accuracy: 0.9750 - val_loss: 0.1039 - val_accuracy: 0.9667\n",
      "Epoch 52/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0883 - accuracy: 0.9750 - val_loss: 0.1034 - val_accuracy: 0.9667\n",
      "Epoch 53/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0880 - accuracy: 0.9750 - val_loss: 0.1033 - val_accuracy: 0.9667\n",
      "Epoch 54/1000\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.0879 - accuracy: 0.9750 - val_loss: 0.1036 - val_accuracy: 0.9667\n",
      "Epoch 55/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.0879 - accuracy: 0.9750 - val_loss: 0.1039 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0879 - accuracy: 0.9750 - val_loss: 0.1035 - val_accuracy: 0.9667\n",
      "Epoch 57/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0878 - accuracy: 0.9750 - val_loss: 0.1039 - val_accuracy: 0.9667\n",
      "Epoch 58/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.1039 - val_accuracy: 0.9667\n",
      "Epoch 59/1000\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.1035 - val_accuracy: 0.9667\n",
      "Epoch 60/1000\n",
      "120/120 [==============================] - 0s 332us/sample - loss: 0.0875 - accuracy: 0.9750 - val_loss: 0.1031 - val_accuracy: 0.9667\n",
      "Epoch 61/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0872 - accuracy: 0.9750 - val_loss: 0.1030 - val_accuracy: 0.9667\n",
      "Epoch 62/1000\n",
      "120/120 [==============================] - 0s 299us/sample - loss: 0.0872 - accuracy: 0.9750 - val_loss: 0.1029 - val_accuracy: 0.9667\n",
      "Epoch 63/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.0871 - accuracy: 0.9750 - val_loss: 0.1030 - val_accuracy: 0.9667\n",
      "Epoch 64/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0870 - accuracy: 0.9750 - val_loss: 0.1029 - val_accuracy: 0.9667\n",
      "Epoch 65/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0868 - accuracy: 0.9750 - val_loss: 0.1025 - val_accuracy: 0.9667\n",
      "Epoch 66/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0868 - accuracy: 0.9750 - val_loss: 0.1022 - val_accuracy: 0.9667\n",
      "Epoch 67/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0867 - accuracy: 0.9750 - val_loss: 0.1021 - val_accuracy: 0.9667\n",
      "Epoch 68/1000\n",
      "120/120 [==============================] - 0s 266us/sample - loss: 0.0866 - accuracy: 0.9750 - val_loss: 0.1019 - val_accuracy: 0.9667\n",
      "Epoch 69/1000\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.0865 - accuracy: 0.9750 - val_loss: 0.1019 - val_accuracy: 0.9667\n",
      "Epoch 70/1000\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.0864 - accuracy: 0.9750 - val_loss: 0.1017 - val_accuracy: 0.9667\n",
      "Epoch 71/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0866 - accuracy: 0.9750 - val_loss: 0.1012 - val_accuracy: 0.9667\n",
      "Epoch 72/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0862 - accuracy: 0.9667 - val_loss: 0.1014 - val_accuracy: 0.9667\n",
      "Epoch 73/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 74/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0860 - accuracy: 0.9750 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 75/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0859 - accuracy: 0.9750 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 76/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.1015 - val_accuracy: 0.9667\n",
      "Epoch 77/1000\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.0858 - accuracy: 0.9750 - val_loss: 0.1015 - val_accuracy: 0.9667\n",
      "Epoch 78/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0857 - accuracy: 0.9750 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 79/1000\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.1016 - val_accuracy: 0.9667\n",
      "Epoch 80/1000\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.1015 - val_accuracy: 0.9667\n",
      "Epoch 81/1000\n",
      "120/120 [==============================] - 0s 166us/sample - loss: 0.0856 - accuracy: 0.9750 - val_loss: 0.1019 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x203336346c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train,y=y_train,epochs=1000,\n",
    "          validation_data=(scaled_X_test,y_test),callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093571</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093637</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.108967</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093371</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.108841</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.108757</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093102</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.108427</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.085816</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.101540</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.085670</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.101638</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.085534</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.101587</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.085467</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.101550</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.085624</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.101881</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   0.093571  0.966667  0.108632      0.966667\n",
       "1   0.093637  0.966667  0.108967      0.966667\n",
       "2   0.093371  0.975000  0.108841      0.966667\n",
       "3   0.093333  0.975000  0.108757      0.966667\n",
       "4   0.093102  0.975000  0.108427      0.966667\n",
       "..       ...       ...       ...           ...\n",
       "76  0.085816  0.975000  0.101540      0.966667\n",
       "77  0.085670  0.975000  0.101638      0.966667\n",
       "78  0.085534  0.975000  0.101587      0.966667\n",
       "79  0.085467  0.975000  0.101550      0.966667\n",
       "80  0.085624  0.975000  0.101881      0.966667\n",
       "\n",
       "[81 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x203335dee88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x203344206c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10188092291355133, 0.96666664]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X =scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=4,activation='relu',input_shape=[4,]))\n",
    "model.add(Dense(units=3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/980\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 1.0998 - accuracy: 0.3333\n",
      "Epoch 2/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0952 - accuracy: 0.3333\n",
      "Epoch 3/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0914 - accuracy: 0.3333\n",
      "Epoch 4/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0875 - accuracy: 0.3333\n",
      "Epoch 5/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 1.0837 - accuracy: 0.3333\n",
      "Epoch 6/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 1.0801 - accuracy: 0.3333\n",
      "Epoch 7/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0763 - accuracy: 0.3333\n",
      "Epoch 8/980\n",
      "150/150 [==============================] - 0s 219us/sample - loss: 1.0727 - accuracy: 0.3333\n",
      "Epoch 9/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0693 - accuracy: 0.3333\n",
      "Epoch 10/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 1.0656 - accuracy: 0.3333\n",
      "Epoch 11/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0621 - accuracy: 0.3333\n",
      "Epoch 12/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0586 - accuracy: 0.3333\n",
      "Epoch 13/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 1.0551 - accuracy: 0.3333\n",
      "Epoch 14/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0516 - accuracy: 0.3400\n",
      "Epoch 15/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0481 - accuracy: 0.3400\n",
      "Epoch 16/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0445 - accuracy: 0.3533\n",
      "Epoch 17/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0409 - accuracy: 0.3667\n",
      "Epoch 18/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0373 - accuracy: 0.3733\n",
      "Epoch 19/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0337 - accuracy: 0.4000\n",
      "Epoch 20/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0298 - accuracy: 0.4267\n",
      "Epoch 21/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.40 - 0s 100us/sample - loss: 1.0263 - accuracy: 0.4667\n",
      "Epoch 22/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 1.0221 - accuracy: 0.4933\n",
      "Epoch 23/980\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 1.0182 - accuracy: 0.5333\n",
      "Epoch 24/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 1.0141 - accuracy: 0.5667\n",
      "Epoch 25/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0100 - accuracy: 0.5867\n",
      "Epoch 26/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 1.0056 - accuracy: 0.6067\n",
      "Epoch 27/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0014 - accuracy: 0.6200\n",
      "Epoch 28/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9968 - accuracy: 0.6400\n",
      "Epoch 29/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9923 - accuracy: 0.6467\n",
      "Epoch 30/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9874 - accuracy: 0.6400\n",
      "Epoch 31/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9828 - accuracy: 0.6400\n",
      "Epoch 32/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9778 - accuracy: 0.6333\n",
      "Epoch 33/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9727 - accuracy: 0.6333\n",
      "Epoch 34/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9677 - accuracy: 0.6333\n",
      "Epoch 35/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.9623 - accuracy: 0.6400\n",
      "Epoch 36/980\n",
      "150/150 [==============================] - 0s 206us/sample - loss: 0.9568 - accuracy: 0.6533\n",
      "Epoch 37/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.9511 - accuracy: 0.6533\n",
      "Epoch 38/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9455 - accuracy: 0.6600\n",
      "Epoch 39/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9393 - accuracy: 0.6733\n",
      "Epoch 40/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9332 - accuracy: 0.6667\n",
      "Epoch 41/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9273 - accuracy: 0.6800\n",
      "Epoch 42/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9207 - accuracy: 0.7467\n",
      "Epoch 43/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9149 - accuracy: 0.7533\n",
      "Epoch 44/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9082 - accuracy: 0.7600\n",
      "Epoch 45/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9018 - accuracy: 0.7400\n",
      "Epoch 46/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8955 - accuracy: 0.7267\n",
      "Epoch 47/980\n",
      "150/150 [==============================] - 0s 180us/sample - loss: 0.8890 - accuracy: 0.7333\n",
      "Epoch 48/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8826 - accuracy: 0.7133\n",
      "Epoch 49/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8759 - accuracy: 0.6867\n",
      "Epoch 50/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8694 - accuracy: 0.6867\n",
      "Epoch 51/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8630 - accuracy: 0.6800\n",
      "Epoch 52/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8565 - accuracy: 0.6733\n",
      "Epoch 53/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8499 - accuracy: 0.6667\n",
      "Epoch 54/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8436 - accuracy: 0.6667\n",
      "Epoch 55/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.8369 - accuracy: 0.6667\n",
      "Epoch 56/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8302 - accuracy: 0.6667\n",
      "Epoch 57/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.8237 - accuracy: 0.6667\n",
      "Epoch 58/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8174 - accuracy: 0.6667\n",
      "Epoch 59/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.8109 - accuracy: 0.6667\n",
      "Epoch 60/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.8045 - accuracy: 0.6667\n",
      "Epoch 61/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.7981 - accuracy: 0.6667\n",
      "Epoch 62/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7918 - accuracy: 0.6667\n",
      "Epoch 63/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7857 - accuracy: 0.6667\n",
      "Epoch 64/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7795 - accuracy: 0.6667\n",
      "Epoch 65/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7734 - accuracy: 0.6667\n",
      "Epoch 66/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7673 - accuracy: 0.6667\n",
      "Epoch 67/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7613 - accuracy: 0.6667\n",
      "Epoch 68/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7556 - accuracy: 0.6667\n",
      "Epoch 69/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7494 - accuracy: 0.6667\n",
      "Epoch 70/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7437 - accuracy: 0.6667\n",
      "Epoch 71/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7379 - accuracy: 0.6667\n",
      "Epoch 72/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7324 - accuracy: 0.6667\n",
      "Epoch 73/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7268 - accuracy: 0.6667\n",
      "Epoch 74/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7213 - accuracy: 0.6667\n",
      "Epoch 75/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7157 - accuracy: 0.6667\n",
      "Epoch 76/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7105 - accuracy: 0.6667\n",
      "Epoch 77/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7050 - accuracy: 0.6667\n",
      "Epoch 78/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6998 - accuracy: 0.6667\n",
      "Epoch 79/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6947 - accuracy: 0.6667\n",
      "Epoch 80/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6897 - accuracy: 0.6667\n",
      "Epoch 81/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6845 - accuracy: 0.6667\n",
      "Epoch 82/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6798 - accuracy: 0.6667\n",
      "Epoch 83/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6747 - accuracy: 0.6667\n",
      "Epoch 84/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6700 - accuracy: 0.6667\n",
      "Epoch 85/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6652 - accuracy: 0.6667\n",
      "Epoch 86/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6605 - accuracy: 0.6667\n",
      "Epoch 87/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6559 - accuracy: 0.6667\n",
      "Epoch 88/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.6514 - accuracy: 0.6667\n",
      "Epoch 89/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6469 - accuracy: 0.6667\n",
      "Epoch 90/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.6424 - accuracy: 0.6667\n",
      "Epoch 91/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.6381 - accuracy: 0.6667\n",
      "Epoch 92/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6338 - accuracy: 0.6733\n",
      "Epoch 93/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6296 - accuracy: 0.6733\n",
      "Epoch 94/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6256 - accuracy: 0.6733\n",
      "Epoch 95/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6213 - accuracy: 0.6733\n",
      "Epoch 96/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6175 - accuracy: 0.6733\n",
      "Epoch 97/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6135 - accuracy: 0.6733\n",
      "Epoch 98/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6096 - accuracy: 0.6800\n",
      "Epoch 99/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6059 - accuracy: 0.6800\n",
      "Epoch 100/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.6021 - accuracy: 0.6800\n",
      "Epoch 101/980\n",
      "150/150 [==============================] - 0s 239us/sample - loss: 0.5983 - accuracy: 0.6800\n",
      "Epoch 102/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5947 - accuracy: 0.6800\n",
      "Epoch 103/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5913 - accuracy: 0.6800\n",
      "Epoch 104/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5876 - accuracy: 0.6800\n",
      "Epoch 105/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5843 - accuracy: 0.6800\n",
      "Epoch 106/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5809 - accuracy: 0.6867\n",
      "Epoch 107/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5775 - accuracy: 0.6933\n",
      "Epoch 108/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5743 - accuracy: 0.6933\n",
      "Epoch 109/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5710 - accuracy: 0.6933\n",
      "Epoch 110/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5679 - accuracy: 0.6933\n",
      "Epoch 111/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5647 - accuracy: 0.6933\n",
      "Epoch 112/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5616 - accuracy: 0.6933\n",
      "Epoch 113/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5587 - accuracy: 0.7000\n",
      "Epoch 114/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.5558 - accuracy: 0.7000\n",
      "Epoch 115/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5527 - accuracy: 0.7000\n",
      "Epoch 116/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5497 - accuracy: 0.7000\n",
      "Epoch 117/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5473 - accuracy: 0.7000\n",
      "Epoch 118/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5441 - accuracy: 0.7000\n",
      "Epoch 119/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5413 - accuracy: 0.7000\n",
      "Epoch 120/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5388 - accuracy: 0.7067\n",
      "Epoch 121/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5361 - accuracy: 0.7067\n",
      "Epoch 122/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5334 - accuracy: 0.7067\n",
      "Epoch 123/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5308 - accuracy: 0.7067\n",
      "Epoch 124/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.5282 - accuracy: 0.7067\n",
      "Epoch 125/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5257 - accuracy: 0.7067\n",
      "Epoch 126/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5232 - accuracy: 0.7067\n",
      "Epoch 127/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5208 - accuracy: 0.7133\n",
      "Epoch 128/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5185 - accuracy: 0.7133\n",
      "Epoch 129/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.5160 - accuracy: 0.7267\n",
      "Epoch 130/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5136 - accuracy: 0.7267\n",
      "Epoch 131/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.5113 - accuracy: 0.7267\n",
      "Epoch 132/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.87 - 0s 80us/sample - loss: 0.5091 - accuracy: 0.7267\n",
      "Epoch 133/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5068 - accuracy: 0.7333\n",
      "Epoch 134/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5045 - accuracy: 0.7400\n",
      "Epoch 135/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5023 - accuracy: 0.7400\n",
      "Epoch 136/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5002 - accuracy: 0.7467\n",
      "Epoch 137/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4981 - accuracy: 0.7533\n",
      "Epoch 138/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4959 - accuracy: 0.7733\n",
      "Epoch 139/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4939 - accuracy: 0.7733\n",
      "Epoch 140/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4920 - accuracy: 0.7733\n",
      "Epoch 141/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4897 - accuracy: 0.7733\n",
      "Epoch 142/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4877 - accuracy: 0.7733\n",
      "Epoch 143/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4856 - accuracy: 0.7733\n",
      "Epoch 144/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.4837 - accuracy: 0.7733\n",
      "Epoch 145/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4817 - accuracy: 0.7733\n",
      "Epoch 146/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4798 - accuracy: 0.7733\n",
      "Epoch 147/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4779 - accuracy: 0.7800\n",
      "Epoch 148/980\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4760 - accuracy: 0.7867\n",
      "Epoch 149/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4741 - accuracy: 0.7933\n",
      "Epoch 150/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4723 - accuracy: 0.7933\n",
      "Epoch 151/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4704 - accuracy: 0.7933\n",
      "Epoch 152/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4686 - accuracy: 0.8067\n",
      "Epoch 153/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4668 - accuracy: 0.8133\n",
      "Epoch 154/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4650 - accuracy: 0.8133\n",
      "Epoch 155/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4634 - accuracy: 0.8133\n",
      "Epoch 156/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4615 - accuracy: 0.8133\n",
      "Epoch 157/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4597 - accuracy: 0.8267\n",
      "Epoch 158/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4582 - accuracy: 0.8333\n",
      "Epoch 159/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.4563 - accuracy: 0.8400\n",
      "Epoch 160/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4548 - accuracy: 0.8400\n",
      "Epoch 161/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4531 - accuracy: 0.8400\n",
      "Epoch 162/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4512 - accuracy: 0.8400\n",
      "Epoch 163/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.4496 - accuracy: 0.8400\n",
      "Epoch 164/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4481 - accuracy: 0.8400\n",
      "Epoch 165/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4465 - accuracy: 0.8400\n",
      "Epoch 166/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4449 - accuracy: 0.8400\n",
      "Epoch 167/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4432 - accuracy: 0.8467\n",
      "Epoch 168/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4417 - accuracy: 0.8467\n",
      "Epoch 169/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4400 - accuracy: 0.8467\n",
      "Epoch 170/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4384 - accuracy: 0.8533\n",
      "Epoch 171/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4373 - accuracy: 0.8667\n",
      "Epoch 172/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4353 - accuracy: 0.8800\n",
      "Epoch 173/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4338 - accuracy: 0.8800\n",
      "Epoch 174/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4325 - accuracy: 0.8733\n",
      "Epoch 175/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4308 - accuracy: 0.8800\n",
      "Epoch 176/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4292 - accuracy: 0.8800\n",
      "Epoch 177/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4278 - accuracy: 0.8800\n",
      "Epoch 178/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4262 - accuracy: 0.8800\n",
      "Epoch 179/980\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4248 - accuracy: 0.8933\n",
      "Epoch 180/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4232 - accuracy: 0.9000\n",
      "Epoch 181/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4218 - accuracy: 0.9000\n",
      "Epoch 182/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4203 - accuracy: 0.9000\n",
      "Epoch 183/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4189 - accuracy: 0.9000\n",
      "Epoch 184/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4174 - accuracy: 0.9000\n",
      "Epoch 185/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4160 - accuracy: 0.9000\n",
      "Epoch 186/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4146 - accuracy: 0.9000\n",
      "Epoch 187/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.4131 - accuracy: 0.9000\n",
      "Epoch 188/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.4117 - accuracy: 0.9000\n",
      "Epoch 189/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.4103 - accuracy: 0.9000\n",
      "Epoch 190/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4088 - accuracy: 0.9000\n",
      "Epoch 191/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4074 - accuracy: 0.9000\n",
      "Epoch 192/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4060 - accuracy: 0.9133\n",
      "Epoch 193/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4046 - accuracy: 0.9200\n",
      "Epoch 194/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4032 - accuracy: 0.9267\n",
      "Epoch 195/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4019 - accuracy: 0.9133\n",
      "Epoch 196/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4005 - accuracy: 0.9267\n",
      "Epoch 197/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3991 - accuracy: 0.9333\n",
      "Epoch 198/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3978 - accuracy: 0.9333\n",
      "Epoch 199/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3963 - accuracy: 0.9400\n",
      "Epoch 200/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.3950 - accuracy: 0.9400\n",
      "Epoch 201/980\n",
      "150/150 [==============================] - 0s 273us/sample - loss: 0.3936 - accuracy: 0.9400\n",
      "Epoch 202/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3922 - accuracy: 0.9400\n",
      "Epoch 203/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3909 - accuracy: 0.9400\n",
      "Epoch 204/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3896 - accuracy: 0.9400\n",
      "Epoch 205/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3881 - accuracy: 0.9400\n",
      "Epoch 206/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3870 - accuracy: 0.9400\n",
      "Epoch 207/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3855 - accuracy: 0.9400\n",
      "Epoch 208/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3841 - accuracy: 0.9400\n",
      "Epoch 209/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3828 - accuracy: 0.9400\n",
      "Epoch 210/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3815 - accuracy: 0.9400\n",
      "Epoch 211/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3802 - accuracy: 0.9467\n",
      "Epoch 212/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.3789 - accuracy: 0.9467\n",
      "Epoch 213/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3776 - accuracy: 0.9400\n",
      "Epoch 214/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3765 - accuracy: 0.9400\n",
      "Epoch 215/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3750 - accuracy: 0.9400\n",
      "Epoch 216/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3738 - accuracy: 0.9467\n",
      "Epoch 217/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3724 - accuracy: 0.9533\n",
      "Epoch 218/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3713 - accuracy: 0.9667\n",
      "Epoch 219/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3699 - accuracy: 0.9667\n",
      "Epoch 220/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3686 - accuracy: 0.9667\n",
      "Epoch 221/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3674 - accuracy: 0.9667\n",
      "Epoch 222/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3661 - accuracy: 0.9667\n",
      "Epoch 223/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3648 - accuracy: 0.9667\n",
      "Epoch 224/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3636 - accuracy: 0.9667\n",
      "Epoch 225/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3624 - accuracy: 0.9667\n",
      "Epoch 226/980\n",
      "150/150 [==============================] - 0s 180us/sample - loss: 0.3612 - accuracy: 0.9667\n",
      "Epoch 227/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3598 - accuracy: 0.9667\n",
      "Epoch 228/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3585 - accuracy: 0.9667\n",
      "Epoch 229/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3573 - accuracy: 0.9667\n",
      "Epoch 230/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3560 - accuracy: 0.9667\n",
      "Epoch 231/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3548 - accuracy: 0.9667\n",
      "Epoch 232/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3537 - accuracy: 0.9667\n",
      "Epoch 233/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3526 - accuracy: 0.9667\n",
      "Epoch 234/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3511 - accuracy: 0.9667\n",
      "Epoch 235/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3500 - accuracy: 0.9667\n",
      "Epoch 236/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3487 - accuracy: 0.9667\n",
      "Epoch 237/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3474 - accuracy: 0.9667\n",
      "Epoch 238/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3462 - accuracy: 0.9667\n",
      "Epoch 239/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3452 - accuracy: 0.9667\n",
      "Epoch 240/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3438 - accuracy: 0.9667\n",
      "Epoch 241/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3427 - accuracy: 0.9667\n",
      "Epoch 242/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3415 - accuracy: 0.9667\n",
      "Epoch 243/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3402 - accuracy: 0.9667\n",
      "Epoch 244/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3390 - accuracy: 0.9667\n",
      "Epoch 245/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3379 - accuracy: 0.9667\n",
      "Epoch 246/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3367 - accuracy: 0.9667\n",
      "Epoch 247/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 1.00 - 0s 80us/sample - loss: 0.3355 - accuracy: 0.9667\n",
      "Epoch 248/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3344 - accuracy: 0.9667\n",
      "Epoch 249/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3331 - accuracy: 0.9667\n",
      "Epoch 250/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3320 - accuracy: 0.9667\n",
      "Epoch 251/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3308 - accuracy: 0.9667\n",
      "Epoch 252/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3299 - accuracy: 0.9667\n",
      "Epoch 253/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3284 - accuracy: 0.9667\n",
      "Epoch 254/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3273 - accuracy: 0.9667\n",
      "Epoch 255/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3267 - accuracy: 0.9667\n",
      "Epoch 256/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3251 - accuracy: 0.9667\n",
      "Epoch 257/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3239 - accuracy: 0.9667\n",
      "Epoch 258/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3228 - accuracy: 0.9667\n",
      "Epoch 259/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3217 - accuracy: 0.9667\n",
      "Epoch 260/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3204 - accuracy: 0.9667\n",
      "Epoch 261/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3195 - accuracy: 0.9667\n",
      "Epoch 262/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3183 - accuracy: 0.9667\n",
      "Epoch 263/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3172 - accuracy: 0.9667\n",
      "Epoch 264/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3162 - accuracy: 0.9667\n",
      "Epoch 265/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3151 - accuracy: 0.9667\n",
      "Epoch 266/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3139 - accuracy: 0.9667\n",
      "Epoch 267/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3129 - accuracy: 0.9667\n",
      "Epoch 268/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3117 - accuracy: 0.9667\n",
      "Epoch 269/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3112 - accuracy: 0.9667\n",
      "Epoch 270/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3096 - accuracy: 0.9667\n",
      "Epoch 271/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3084 - accuracy: 0.9667\n",
      "Epoch 272/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3074 - accuracy: 0.9667\n",
      "Epoch 273/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3063 - accuracy: 0.9667\n",
      "Epoch 274/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3052 - accuracy: 0.9667\n",
      "Epoch 275/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3043 - accuracy: 0.9667\n",
      "Epoch 276/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.3031 - accuracy: 0.9667\n",
      "Epoch 277/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3021 - accuracy: 0.9667\n",
      "Epoch 278/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3011 - accuracy: 0.9667\n",
      "Epoch 279/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3000 - accuracy: 0.9667\n",
      "Epoch 280/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2990 - accuracy: 0.9667\n",
      "Epoch 281/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2979 - accuracy: 0.9667\n",
      "Epoch 282/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2969 - accuracy: 0.9667\n",
      "Epoch 283/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2960 - accuracy: 0.9667\n",
      "Epoch 284/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.2948 - accuracy: 0.9667\n",
      "Epoch 285/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.2939 - accuracy: 0.9667\n",
      "Epoch 286/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2928 - accuracy: 0.9667\n",
      "Epoch 287/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2918 - accuracy: 0.9667\n",
      "Epoch 288/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2907 - accuracy: 0.9667\n",
      "Epoch 289/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2900 - accuracy: 0.9667\n",
      "Epoch 290/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2887 - accuracy: 0.9667\n",
      "Epoch 291/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2877 - accuracy: 0.9667\n",
      "Epoch 292/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2867 - accuracy: 0.9667\n",
      "Epoch 293/980\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.2858 - accuracy: 0.9667\n",
      "Epoch 294/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.2848 - accuracy: 0.9667\n",
      "Epoch 295/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.2837 - accuracy: 0.9667\n",
      "Epoch 296/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2828 - accuracy: 0.9667\n",
      "Epoch 297/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2817 - accuracy: 0.9667\n",
      "Epoch 298/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.2808 - accuracy: 0.9667\n",
      "Epoch 299/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.2799 - accuracy: 0.9667\n",
      "Epoch 300/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2789 - accuracy: 0.9667\n",
      "Epoch 301/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2779 - accuracy: 0.9667\n",
      "Epoch 302/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2769 - accuracy: 0.9667\n",
      "Epoch 303/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2760 - accuracy: 0.9667\n",
      "Epoch 304/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2751 - accuracy: 0.9667\n",
      "Epoch 305/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2741 - accuracy: 0.9667\n",
      "Epoch 306/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2731 - accuracy: 0.9667\n",
      "Epoch 307/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2722 - accuracy: 0.9667\n",
      "Epoch 308/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2713 - accuracy: 0.9667\n",
      "Epoch 309/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2704 - accuracy: 0.9667\n",
      "Epoch 310/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2693 - accuracy: 0.9667\n",
      "Epoch 311/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2685 - accuracy: 0.9667\n",
      "Epoch 312/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2676 - accuracy: 0.9667\n",
      "Epoch 313/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2666 - accuracy: 0.9667\n",
      "Epoch 314/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2657 - accuracy: 0.9667\n",
      "Epoch 315/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2647 - accuracy: 0.9667\n",
      "Epoch 316/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2638 - accuracy: 0.9667\n",
      "Epoch 317/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2630 - accuracy: 0.9667\n",
      "Epoch 318/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2620 - accuracy: 0.9667\n",
      "Epoch 319/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2613 - accuracy: 0.9667\n",
      "Epoch 320/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2602 - accuracy: 0.9667\n",
      "Epoch 321/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2594 - accuracy: 0.9667\n",
      "Epoch 322/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2585 - accuracy: 0.9667\n",
      "Epoch 323/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2575 - accuracy: 0.9667\n",
      "Epoch 324/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2567 - accuracy: 0.9667\n",
      "Epoch 325/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2558 - accuracy: 0.9667\n",
      "Epoch 326/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2551 - accuracy: 0.9667\n",
      "Epoch 327/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2541 - accuracy: 0.9667\n",
      "Epoch 328/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.2532 - accuracy: 0.9667\n",
      "Epoch 329/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2523 - accuracy: 0.9667\n",
      "Epoch 330/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2516 - accuracy: 0.9667\n",
      "Epoch 331/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2506 - accuracy: 0.9667\n",
      "Epoch 332/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2497 - accuracy: 0.9667\n",
      "Epoch 333/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2489 - accuracy: 0.9733\n",
      "Epoch 334/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2481 - accuracy: 0.9733\n",
      "Epoch 335/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2473 - accuracy: 0.9733\n",
      "Epoch 336/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2464 - accuracy: 0.9733\n",
      "Epoch 337/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2456 - accuracy: 0.9733\n",
      "Epoch 338/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2448 - accuracy: 0.9733\n",
      "Epoch 339/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2439 - accuracy: 0.9733\n",
      "Epoch 340/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2431 - accuracy: 0.9733\n",
      "Epoch 341/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2422 - accuracy: 0.9733\n",
      "Epoch 342/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2414 - accuracy: 0.9733\n",
      "Epoch 343/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.2405 - accuracy: 0.9733\n",
      "Epoch 344/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.2398 - accuracy: 0.9733\n",
      "Epoch 345/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2390 - accuracy: 0.9667\n",
      "Epoch 346/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2382 - accuracy: 0.9733\n",
      "Epoch 347/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2373 - accuracy: 0.9733\n",
      "Epoch 348/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2365 - accuracy: 0.9733\n",
      "Epoch 349/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2358 - accuracy: 0.9733\n",
      "Epoch 350/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2350 - accuracy: 0.9733\n",
      "Epoch 351/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2341 - accuracy: 0.9733\n",
      "Epoch 352/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2335 - accuracy: 0.9733\n",
      "Epoch 353/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.2327 - accuracy: 0.9733\n",
      "Epoch 354/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2318 - accuracy: 0.9733\n",
      "Epoch 355/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2310 - accuracy: 0.9733\n",
      "Epoch 356/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2304 - accuracy: 0.9733\n",
      "Epoch 357/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2295 - accuracy: 0.9733\n",
      "Epoch 358/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2288 - accuracy: 0.9733\n",
      "Epoch 359/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.2281 - accuracy: 0.9733\n",
      "Epoch 360/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.2273 - accuracy: 0.9733\n",
      "Epoch 361/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2265 - accuracy: 0.9733\n",
      "Epoch 362/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.2258 - accuracy: 0.9733\n",
      "Epoch 363/980\n",
      "150/150 [==============================] - 0s 199us/sample - loss: 0.2254 - accuracy: 0.9733\n",
      "Epoch 364/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.2242 - accuracy: 0.9733\n",
      "Epoch 365/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2235 - accuracy: 0.9733\n",
      "Epoch 366/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2227 - accuracy: 0.9733\n",
      "Epoch 367/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2220 - accuracy: 0.9733\n",
      "Epoch 368/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.2214 - accuracy: 0.9733\n",
      "Epoch 369/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2205 - accuracy: 0.9733\n",
      "Epoch 370/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2198 - accuracy: 0.9733\n",
      "Epoch 371/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2192 - accuracy: 0.9733\n",
      "Epoch 372/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.2184 - accuracy: 0.9733\n",
      "Epoch 373/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2177 - accuracy: 0.9733\n",
      "Epoch 374/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2170 - accuracy: 0.9733\n",
      "Epoch 375/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2163 - accuracy: 0.9733\n",
      "Epoch 376/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2156 - accuracy: 0.9733\n",
      "Epoch 377/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2149 - accuracy: 0.9733\n",
      "Epoch 378/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2142 - accuracy: 0.9733\n",
      "Epoch 379/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2137 - accuracy: 0.9733\n",
      "Epoch 380/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2128 - accuracy: 0.9733\n",
      "Epoch 381/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2121 - accuracy: 0.9733\n",
      "Epoch 382/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2116 - accuracy: 0.9733\n",
      "Epoch 383/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2109 - accuracy: 0.9733\n",
      "Epoch 384/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.2101 - accuracy: 0.9733\n",
      "Epoch 385/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2094 - accuracy: 0.9733\n",
      "Epoch 386/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2088 - accuracy: 0.9733\n",
      "Epoch 387/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2081 - accuracy: 0.9733\n",
      "Epoch 388/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2074 - accuracy: 0.9733\n",
      "Epoch 389/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2067 - accuracy: 0.9733\n",
      "Epoch 390/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2061 - accuracy: 0.9733\n",
      "Epoch 391/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2054 - accuracy: 0.9733\n",
      "Epoch 392/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.2048 - accuracy: 0.9733\n",
      "Epoch 393/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2041 - accuracy: 0.9733\n",
      "Epoch 394/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2035 - accuracy: 0.9733\n",
      "Epoch 395/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2029 - accuracy: 0.9733\n",
      "Epoch 396/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.2022 - accuracy: 0.9733\n",
      "Epoch 397/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.2016 - accuracy: 0.9733\n",
      "Epoch 398/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.2009 - accuracy: 0.9733\n",
      "Epoch 399/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.2003 - accuracy: 0.9733\n",
      "Epoch 400/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1996 - accuracy: 0.9733\n",
      "Epoch 401/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1990 - accuracy: 0.9733\n",
      "Epoch 402/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1984 - accuracy: 0.9733\n",
      "Epoch 403/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1979 - accuracy: 0.9733\n",
      "Epoch 404/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1972 - accuracy: 0.9733\n",
      "Epoch 405/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1966 - accuracy: 0.9733\n",
      "Epoch 406/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1960 - accuracy: 0.9733\n",
      "Epoch 407/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1954 - accuracy: 0.9733\n",
      "Epoch 408/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1948 - accuracy: 0.9733\n",
      "Epoch 409/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1941 - accuracy: 0.9733\n",
      "Epoch 410/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1935 - accuracy: 0.9733\n",
      "Epoch 411/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1930 - accuracy: 0.9733\n",
      "Epoch 412/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1924 - accuracy: 0.9733\n",
      "Epoch 413/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1918 - accuracy: 0.9733\n",
      "Epoch 414/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1912 - accuracy: 0.9733\n",
      "Epoch 415/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1906 - accuracy: 0.9733\n",
      "Epoch 416/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1900 - accuracy: 0.9733\n",
      "Epoch 417/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1895 - accuracy: 0.9733\n",
      "Epoch 418/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1889 - accuracy: 0.9733\n",
      "Epoch 419/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 1.00 - 0s 86us/sample - loss: 0.1884 - accuracy: 0.9733\n",
      "Epoch 420/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1879 - accuracy: 0.9733\n",
      "Epoch 421/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1873 - accuracy: 0.9733\n",
      "Epoch 422/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1867 - accuracy: 0.9667\n",
      "Epoch 423/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1862 - accuracy: 0.9667\n",
      "Epoch 424/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1855 - accuracy: 0.9733\n",
      "Epoch 425/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1851 - accuracy: 0.9733\n",
      "Epoch 426/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1844 - accuracy: 0.9733\n",
      "Epoch 427/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1839 - accuracy: 0.9733\n",
      "Epoch 428/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.1834 - accuracy: 0.9667\n",
      "Epoch 429/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.1831 - accuracy: 0.9733\n",
      "Epoch 430/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1822 - accuracy: 0.9733\n",
      "Epoch 431/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1819 - accuracy: 0.9733\n",
      "Epoch 432/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1811 - accuracy: 0.9667\n",
      "Epoch 433/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1806 - accuracy: 0.9667\n",
      "Epoch 434/980\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.1801 - accuracy: 0.9667\n",
      "Epoch 435/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1796 - accuracy: 0.9733\n",
      "Epoch 436/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1792 - accuracy: 0.9667\n",
      "Epoch 437/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1785 - accuracy: 0.9667\n",
      "Epoch 438/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1780 - accuracy: 0.9667\n",
      "Epoch 439/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1775 - accuracy: 0.9667\n",
      "Epoch 440/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1770 - accuracy: 0.9733\n",
      "Epoch 441/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1766 - accuracy: 0.9733\n",
      "Epoch 442/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.1760 - accuracy: 0.9733\n",
      "Epoch 443/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1755 - accuracy: 0.9733\n",
      "Epoch 444/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1753 - accuracy: 0.9733\n",
      "Epoch 445/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1745 - accuracy: 0.9733\n",
      "Epoch 446/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1741 - accuracy: 0.9667\n",
      "Epoch 447/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1736 - accuracy: 0.9667\n",
      "Epoch 448/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1729 - accuracy: 0.9667\n",
      "Epoch 449/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1725 - accuracy: 0.9667\n",
      "Epoch 450/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1724 - accuracy: 0.9667\n",
      "Epoch 451/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1717 - accuracy: 0.9667\n",
      "Epoch 452/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1710 - accuracy: 0.9667\n",
      "Epoch 453/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1706 - accuracy: 0.9667\n",
      "Epoch 454/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1701 - accuracy: 0.9667\n",
      "Epoch 455/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1696 - accuracy: 0.9667\n",
      "Epoch 456/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 1.00 - 0s 80us/sample - loss: 0.1692 - accuracy: 0.9667\n",
      "Epoch 457/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1687 - accuracy: 0.9667\n",
      "Epoch 458/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1683 - accuracy: 0.9667\n",
      "Epoch 459/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1678 - accuracy: 0.9667\n",
      "Epoch 460/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1673 - accuracy: 0.9667\n",
      "Epoch 461/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1669 - accuracy: 0.9667\n",
      "Epoch 462/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1665 - accuracy: 0.9667\n",
      "Epoch 463/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1662 - accuracy: 0.9667\n",
      "Epoch 464/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1656 - accuracy: 0.9667\n",
      "Epoch 465/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1651 - accuracy: 0.9667\n",
      "Epoch 466/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1646 - accuracy: 0.9667\n",
      "Epoch 467/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1641 - accuracy: 0.9667\n",
      "Epoch 468/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1637 - accuracy: 0.9667\n",
      "Epoch 469/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.1633 - accuracy: 0.9667\n",
      "Epoch 470/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1629 - accuracy: 0.9667\n",
      "Epoch 471/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1625 - accuracy: 0.9667\n",
      "Epoch 472/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1620 - accuracy: 0.9667\n",
      "Epoch 473/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1618 - accuracy: 0.9667\n",
      "Epoch 474/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1611 - accuracy: 0.9667\n",
      "Epoch 475/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1608 - accuracy: 0.9667\n",
      "Epoch 476/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.1604 - accuracy: 0.9667\n",
      "Epoch 477/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1599 - accuracy: 0.9667\n",
      "Epoch 478/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1596 - accuracy: 0.9667\n",
      "Epoch 479/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1591 - accuracy: 0.9667\n",
      "Epoch 480/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1587 - accuracy: 0.9667\n",
      "Epoch 481/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1583 - accuracy: 0.9667\n",
      "Epoch 482/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.1578 - accuracy: 0.9667\n",
      "Epoch 483/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.1575 - accuracy: 0.9667\n",
      "Epoch 484/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1571 - accuracy: 0.9667\n",
      "Epoch 485/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.1566 - accuracy: 0.9667\n",
      "Epoch 486/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1562 - accuracy: 0.9667\n",
      "Epoch 487/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.1558 - accuracy: 0.9667\n",
      "Epoch 488/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.1554 - accuracy: 0.9667\n",
      "Epoch 489/980\n",
      "150/150 [==============================] - 0s 180us/sample - loss: 0.1551 - accuracy: 0.9667\n",
      "Epoch 490/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.1547 - accuracy: 0.9667\n",
      "Epoch 491/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1543 - accuracy: 0.9667\n",
      "Epoch 492/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1539 - accuracy: 0.9667\n",
      "Epoch 493/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1535 - accuracy: 0.9667\n",
      "Epoch 494/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1531 - accuracy: 0.9667\n",
      "Epoch 495/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1527 - accuracy: 0.9667\n",
      "Epoch 496/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1523 - accuracy: 0.9667\n",
      "Epoch 497/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1519 - accuracy: 0.9667\n",
      "Epoch 498/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1516 - accuracy: 0.9667\n",
      "Epoch 499/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.1511 - accuracy: 0.9667\n",
      "Epoch 500/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1508 - accuracy: 0.9667\n",
      "Epoch 501/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1504 - accuracy: 0.9667\n",
      "Epoch 502/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1500 - accuracy: 0.9667\n",
      "Epoch 503/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1497 - accuracy: 0.9667\n",
      "Epoch 504/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1494 - accuracy: 0.9667\n",
      "Epoch 505/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1489 - accuracy: 0.9667\n",
      "Epoch 506/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1486 - accuracy: 0.9667\n",
      "Epoch 507/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1482 - accuracy: 0.9667\n",
      "Epoch 508/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1480 - accuracy: 0.9667\n",
      "Epoch 509/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1478 - accuracy: 0.9667\n",
      "Epoch 510/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1471 - accuracy: 0.9667\n",
      "Epoch 511/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1469 - accuracy: 0.9667\n",
      "Epoch 512/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.1464 - accuracy: 0.9667\n",
      "Epoch 513/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.1461 - accuracy: 0.9667\n",
      "Epoch 514/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.1461 - accuracy: 0.9667\n",
      "Epoch 515/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1456 - accuracy: 0.9667\n",
      "Epoch 516/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1451 - accuracy: 0.9667\n",
      "Epoch 517/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1448 - accuracy: 0.9667\n",
      "Epoch 518/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1443 - accuracy: 0.9667\n",
      "Epoch 519/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1440 - accuracy: 0.9667\n",
      "Epoch 520/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.96 - 0s 93us/sample - loss: 0.1437 - accuracy: 0.9667\n",
      "Epoch 521/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1434 - accuracy: 0.9667\n",
      "Epoch 522/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1430 - accuracy: 0.9667\n",
      "Epoch 523/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.1427 - accuracy: 0.9667\n",
      "Epoch 524/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1424 - accuracy: 0.9667\n",
      "Epoch 525/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.1421 - accuracy: 0.9667\n",
      "Epoch 526/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1416 - accuracy: 0.9667\n",
      "Epoch 527/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1412 - accuracy: 0.9667\n",
      "Epoch 528/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1410 - accuracy: 0.9667\n",
      "Epoch 529/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1407 - accuracy: 0.9667\n",
      "Epoch 530/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1404 - accuracy: 0.9667\n",
      "Epoch 531/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1400 - accuracy: 0.9667\n",
      "Epoch 532/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1398 - accuracy: 0.9667\n",
      "Epoch 533/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1396 - accuracy: 0.9667\n",
      "Epoch 534/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1391 - accuracy: 0.9667\n",
      "Epoch 535/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1388 - accuracy: 0.9667\n",
      "Epoch 536/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1384 - accuracy: 0.9667\n",
      "Epoch 537/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1382 - accuracy: 0.9667\n",
      "Epoch 538/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1379 - accuracy: 0.9667\n",
      "Epoch 539/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1377 - accuracy: 0.9667\n",
      "Epoch 540/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1373 - accuracy: 0.9667\n",
      "Epoch 541/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1371 - accuracy: 0.9667\n",
      "Epoch 542/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1368 - accuracy: 0.9667\n",
      "Epoch 543/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1363 - accuracy: 0.9667\n",
      "Epoch 544/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.1360 - accuracy: 0.9667\n",
      "Epoch 545/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1357 - accuracy: 0.9667\n",
      "Epoch 546/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1354 - accuracy: 0.9667\n",
      "Epoch 547/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1351 - accuracy: 0.9667\n",
      "Epoch 548/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1347 - accuracy: 0.9667\n",
      "Epoch 549/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1346 - accuracy: 0.9667\n",
      "Epoch 550/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1342 - accuracy: 0.9667\n",
      "Epoch 551/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1339 - accuracy: 0.9667\n",
      "Epoch 552/980\n",
      "150/150 [==============================] - 0s 193us/sample - loss: 0.1337 - accuracy: 0.9667\n",
      "Epoch 553/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1333 - accuracy: 0.9667\n",
      "Epoch 554/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1331 - accuracy: 0.9667\n",
      "Epoch 555/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1328 - accuracy: 0.9667\n",
      "Epoch 556/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1326 - accuracy: 0.9667\n",
      "Epoch 557/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1322 - accuracy: 0.9667\n",
      "Epoch 558/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1320 - accuracy: 0.9667\n",
      "Epoch 559/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1316 - accuracy: 0.9667\n",
      "Epoch 560/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1313 - accuracy: 0.9667\n",
      "Epoch 561/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1312 - accuracy: 0.9667\n",
      "Epoch 562/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1308 - accuracy: 0.9667\n",
      "Epoch 563/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1305 - accuracy: 0.9667\n",
      "Epoch 564/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1302 - accuracy: 0.9667\n",
      "Epoch 565/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1300 - accuracy: 0.9667\n",
      "Epoch 566/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1300 - accuracy: 0.9667\n",
      "Epoch 567/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1296 - accuracy: 0.9667\n",
      "Epoch 568/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1291 - accuracy: 0.9667\n",
      "Epoch 569/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1289 - accuracy: 0.9667\n",
      "Epoch 570/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1286 - accuracy: 0.9667\n",
      "Epoch 571/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1283 - accuracy: 0.9667\n",
      "Epoch 572/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1281 - accuracy: 0.9667\n",
      "Epoch 573/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1277 - accuracy: 0.9667\n",
      "Epoch 574/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1276 - accuracy: 0.9667\n",
      "Epoch 575/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1273 - accuracy: 0.9667\n",
      "Epoch 576/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1271 - accuracy: 0.9667\n",
      "Epoch 577/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1268 - accuracy: 0.9667\n",
      "Epoch 578/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1265 - accuracy: 0.9667\n",
      "Epoch 579/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1263 - accuracy: 0.9667\n",
      "Epoch 580/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1260 - accuracy: 0.9667\n",
      "Epoch 581/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1258 - accuracy: 0.9667\n",
      "Epoch 582/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1255 - accuracy: 0.9667\n",
      "Epoch 583/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1253 - accuracy: 0.9667\n",
      "Epoch 584/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1250 - accuracy: 0.9667\n",
      "Epoch 585/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1247 - accuracy: 0.9667\n",
      "Epoch 586/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1246 - accuracy: 0.9667\n",
      "Epoch 587/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1242 - accuracy: 0.9667\n",
      "Epoch 588/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1240 - accuracy: 0.9667\n",
      "Epoch 589/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.1241 - accuracy: 0.9667\n",
      "Epoch 590/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.1235 - accuracy: 0.9667\n",
      "Epoch 591/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1233 - accuracy: 0.9667\n",
      "Epoch 592/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1230 - accuracy: 0.9667\n",
      "Epoch 593/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1228 - accuracy: 0.9667\n",
      "Epoch 594/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1225 - accuracy: 0.9667\n",
      "Epoch 595/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1223 - accuracy: 0.9667\n",
      "Epoch 596/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.1220 - accuracy: 0.9667\n",
      "Epoch 597/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1218 - accuracy: 0.9667\n",
      "Epoch 598/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1216 - accuracy: 0.9667\n",
      "Epoch 599/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1213 - accuracy: 0.9667\n",
      "Epoch 600/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1211 - accuracy: 0.9667\n",
      "Epoch 601/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1209 - accuracy: 0.9667\n",
      "Epoch 602/980\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.1207 - accuracy: 0.9667\n",
      "Epoch 603/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1205 - accuracy: 0.9667\n",
      "Epoch 604/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1202 - accuracy: 0.9667\n",
      "Epoch 605/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1200 - accuracy: 0.9667\n",
      "Epoch 606/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1197 - accuracy: 0.9667\n",
      "Epoch 607/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1194 - accuracy: 0.9667\n",
      "Epoch 608/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1192 - accuracy: 0.9667\n",
      "Epoch 609/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1190 - accuracy: 0.9667\n",
      "Epoch 610/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1188 - accuracy: 0.9667\n",
      "Epoch 611/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.96 - 0s 93us/sample - loss: 0.1187 - accuracy: 0.9667\n",
      "Epoch 612/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1184 - accuracy: 0.9667\n",
      "Epoch 613/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1181 - accuracy: 0.9667\n",
      "Epoch 614/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1179 - accuracy: 0.9667\n",
      "Epoch 615/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1177 - accuracy: 0.9667\n",
      "Epoch 616/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1177 - accuracy: 0.9667\n",
      "Epoch 617/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.1172 - accuracy: 0.9667\n",
      "Epoch 618/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.1170 - accuracy: 0.9667\n",
      "Epoch 619/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1168 - accuracy: 0.9667\n",
      "Epoch 620/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1166 - accuracy: 0.9667\n",
      "Epoch 621/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1164 - accuracy: 0.9667\n",
      "Epoch 622/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1163 - accuracy: 0.9667\n",
      "Epoch 623/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.1159 - accuracy: 0.9667\n",
      "Epoch 624/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1159 - accuracy: 0.9667\n",
      "Epoch 625/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1155 - accuracy: 0.9667\n",
      "Epoch 626/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1153 - accuracy: 0.9667\n",
      "Epoch 627/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1151 - accuracy: 0.9667\n",
      "Epoch 628/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1149 - accuracy: 0.9667\n",
      "Epoch 629/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1147 - accuracy: 0.9667\n",
      "Epoch 630/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1146 - accuracy: 0.9667\n",
      "Epoch 631/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1146 - accuracy: 0.9667\n",
      "Epoch 632/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1140 - accuracy: 0.9667\n",
      "Epoch 633/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1139 - accuracy: 0.9667\n",
      "Epoch 634/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1137 - accuracy: 0.9667\n",
      "Epoch 635/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1135 - accuracy: 0.9667\n",
      "Epoch 636/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1133 - accuracy: 0.9667\n",
      "Epoch 637/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1131 - accuracy: 0.9667\n",
      "Epoch 638/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1129 - accuracy: 0.9667\n",
      "Epoch 639/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1126 - accuracy: 0.9667\n",
      "Epoch 640/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1125 - accuracy: 0.9667\n",
      "Epoch 641/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1122 - accuracy: 0.9667\n",
      "Epoch 642/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1121 - accuracy: 0.9667\n",
      "Epoch 643/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1118 - accuracy: 0.9667\n",
      "Epoch 644/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1116 - accuracy: 0.9667\n",
      "Epoch 645/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1116 - accuracy: 0.9667\n",
      "Epoch 646/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1113 - accuracy: 0.9667\n",
      "Epoch 647/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1110 - accuracy: 0.9667\n",
      "Epoch 648/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1109 - accuracy: 0.9667\n",
      "Epoch 649/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1106 - accuracy: 0.9667\n",
      "Epoch 650/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1105 - accuracy: 0.9667\n",
      "Epoch 651/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1105 - accuracy: 0.9667\n",
      "Epoch 652/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1101 - accuracy: 0.9667\n",
      "Epoch 653/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1101 - accuracy: 0.9667\n",
      "Epoch 654/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1097 - accuracy: 0.9667\n",
      "Epoch 655/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1096 - accuracy: 0.9667\n",
      "Epoch 656/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1093 - accuracy: 0.9667\n",
      "Epoch 657/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1091 - accuracy: 0.9667\n",
      "Epoch 658/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1090 - accuracy: 0.9667\n",
      "Epoch 659/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1088 - accuracy: 0.9667\n",
      "Epoch 660/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1086 - accuracy: 0.9667\n",
      "Epoch 661/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1085 - accuracy: 0.9667\n",
      "Epoch 662/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1082 - accuracy: 0.9667\n",
      "Epoch 663/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1082 - accuracy: 0.9667\n",
      "Epoch 664/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1079 - accuracy: 0.9667\n",
      "Epoch 665/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1078 - accuracy: 0.9667\n",
      "Epoch 666/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.1075 - accuracy: 0.9667\n",
      "Epoch 667/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.1076 - accuracy: 0.9667\n",
      "Epoch 668/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1072 - accuracy: 0.9667\n",
      "Epoch 669/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1070 - accuracy: 0.9667\n",
      "Epoch 670/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1069 - accuracy: 0.9667\n",
      "Epoch 671/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1067 - accuracy: 0.9667\n",
      "Epoch 672/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1065 - accuracy: 0.9667\n",
      "Epoch 673/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1063 - accuracy: 0.9667\n",
      "Epoch 674/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1061 - accuracy: 0.9667\n",
      "Epoch 675/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1060 - accuracy: 0.9667\n",
      "Epoch 676/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1059 - accuracy: 0.9667\n",
      "Epoch 677/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 678/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1056 - accuracy: 0.9667\n",
      "Epoch 679/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1053 - accuracy: 0.9667\n",
      "Epoch 680/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1051 - accuracy: 0.9667\n",
      "Epoch 681/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.1051 - accuracy: 0.9667\n",
      "Epoch 682/980\n",
      "150/150 [==============================] - 0s 186us/sample - loss: 0.1048 - accuracy: 0.9667\n",
      "Epoch 683/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.1046 - accuracy: 0.9667\n",
      "Epoch 684/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1044 - accuracy: 0.9667\n",
      "Epoch 685/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1043 - accuracy: 0.9667\n",
      "Epoch 686/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1041 - accuracy: 0.9667\n",
      "Epoch 687/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1040 - accuracy: 0.9667\n",
      "Epoch 688/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1038 - accuracy: 0.9667\n",
      "Epoch 689/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1036 - accuracy: 0.9667\n",
      "Epoch 690/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1034 - accuracy: 0.9667\n",
      "Epoch 691/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1033 - accuracy: 0.9667\n",
      "Epoch 692/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1032 - accuracy: 0.9667\n",
      "Epoch 693/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.1031 - accuracy: 0.9667\n",
      "Epoch 694/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1028 - accuracy: 0.9667\n",
      "Epoch 695/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1026 - accuracy: 0.9667\n",
      "Epoch 696/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.1025 - accuracy: 0.9667\n",
      "Epoch 697/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1023 - accuracy: 0.9667\n",
      "Epoch 698/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1022 - accuracy: 0.9667\n",
      "Epoch 699/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1020 - accuracy: 0.9667\n",
      "Epoch 700/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1019 - accuracy: 0.9667\n",
      "Epoch 701/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1017 - accuracy: 0.9667\n",
      "Epoch 702/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1017 - accuracy: 0.9667\n",
      "Epoch 703/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1014 - accuracy: 0.9667\n",
      "Epoch 704/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1012 - accuracy: 0.9667\n",
      "Epoch 705/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1011 - accuracy: 0.9667\n",
      "Epoch 706/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1009 - accuracy: 0.9667\n",
      "Epoch 707/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1008 - accuracy: 0.9667\n",
      "Epoch 708/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.1007 - accuracy: 0.9667\n",
      "Epoch 709/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.1005 - accuracy: 0.9667\n",
      "Epoch 710/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.1004 - accuracy: 0.9667\n",
      "Epoch 711/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.1002 - accuracy: 0.9667\n",
      "Epoch 712/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.1000 - accuracy: 0.9667\n",
      "Epoch 713/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0998 - accuracy: 0.9667\n",
      "Epoch 714/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0998 - accuracy: 0.9667\n",
      "Epoch 715/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0996 - accuracy: 0.9667\n",
      "Epoch 716/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0995 - accuracy: 0.9667\n",
      "Epoch 717/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0992 - accuracy: 0.9667\n",
      "Epoch 718/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0991 - accuracy: 0.9667\n",
      "Epoch 719/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0990 - accuracy: 0.9667\n",
      "Epoch 720/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0989 - accuracy: 0.9667\n",
      "Epoch 721/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0990 - accuracy: 0.9667\n",
      "Epoch 722/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0987 - accuracy: 0.9667\n",
      "Epoch 723/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0984 - accuracy: 0.9667\n",
      "Epoch 724/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0983 - accuracy: 0.9667\n",
      "Epoch 725/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0981 - accuracy: 0.9667\n",
      "Epoch 726/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0980 - accuracy: 0.9667\n",
      "Epoch 727/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.0981 - accuracy: 0.9667\n",
      "Epoch 728/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0977 - accuracy: 0.9667\n",
      "Epoch 729/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0976 - accuracy: 0.9667\n",
      "Epoch 730/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0974 - accuracy: 0.9667\n",
      "Epoch 731/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0974 - accuracy: 0.9667\n",
      "Epoch 732/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0972 - accuracy: 0.9667\n",
      "Epoch 733/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0971 - accuracy: 0.9667\n",
      "Epoch 734/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.0968 - accuracy: 0.9667\n",
      "Epoch 735/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0968 - accuracy: 0.9667\n",
      "Epoch 736/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0966 - accuracy: 0.9667\n",
      "Epoch 737/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0965 - accuracy: 0.9667\n",
      "Epoch 738/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0963 - accuracy: 0.9667\n",
      "Epoch 739/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0964 - accuracy: 0.9667\n",
      "Epoch 740/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0962 - accuracy: 0.9667\n",
      "Epoch 741/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.0959 - accuracy: 0.9667\n",
      "Epoch 742/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.0958 - accuracy: 0.9667\n",
      "Epoch 743/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0957 - accuracy: 0.9667\n",
      "Epoch 744/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0955 - accuracy: 0.9667\n",
      "Epoch 745/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0954 - accuracy: 0.9667\n",
      "Epoch 746/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0953 - accuracy: 0.9667\n",
      "Epoch 747/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0952 - accuracy: 0.9667\n",
      "Epoch 748/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0950 - accuracy: 0.9667\n",
      "Epoch 749/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0949 - accuracy: 0.9667\n",
      "Epoch 750/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0947 - accuracy: 0.9667\n",
      "Epoch 751/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0946 - accuracy: 0.9667\n",
      "Epoch 752/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0945 - accuracy: 0.9667\n",
      "Epoch 753/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0944 - accuracy: 0.9667\n",
      "Epoch 754/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0942 - accuracy: 0.9667\n",
      "Epoch 755/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0941 - accuracy: 0.9667\n",
      "Epoch 756/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0940 - accuracy: 0.9667\n",
      "Epoch 757/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0940 - accuracy: 0.9667\n",
      "Epoch 758/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0938 - accuracy: 0.9667\n",
      "Epoch 759/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0936 - accuracy: 0.9667\n",
      "Epoch 760/980\n",
      "150/150 [==============================] - 0s 199us/sample - loss: 0.0935 - accuracy: 0.9667\n",
      "Epoch 761/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0934 - accuracy: 0.9667\n",
      "Epoch 762/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0932 - accuracy: 0.9667\n",
      "Epoch 763/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0931 - accuracy: 0.9667\n",
      "Epoch 764/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0930 - accuracy: 0.9667\n",
      "Epoch 765/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0929 - accuracy: 0.9667\n",
      "Epoch 766/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0929 - accuracy: 0.9667\n",
      "Epoch 767/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0926 - accuracy: 0.9667\n",
      "Epoch 768/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0925 - accuracy: 0.9667\n",
      "Epoch 769/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0924 - accuracy: 0.9667\n",
      "Epoch 770/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0923 - accuracy: 0.9667\n",
      "Epoch 771/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0921 - accuracy: 0.9667\n",
      "Epoch 772/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0921 - accuracy: 0.9667\n",
      "Epoch 773/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0919 - accuracy: 0.9667\n",
      "Epoch 774/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0918 - accuracy: 0.9667\n",
      "Epoch 775/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0917 - accuracy: 0.9667\n",
      "Epoch 776/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0916 - accuracy: 0.9667\n",
      "Epoch 777/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0914 - accuracy: 0.9667\n",
      "Epoch 778/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0913 - accuracy: 0.9667\n",
      "Epoch 779/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0912 - accuracy: 0.9667\n",
      "Epoch 780/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0910 - accuracy: 0.9667\n",
      "Epoch 781/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0909 - accuracy: 0.9667\n",
      "Epoch 782/980\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.0909 - accuracy: 0.9667\n",
      "Epoch 783/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.0907 - accuracy: 0.9667\n",
      "Epoch 784/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0908 - accuracy: 0.9667\n",
      "Epoch 785/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0905 - accuracy: 0.9667\n",
      "Epoch 786/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0903 - accuracy: 0.9667\n",
      "Epoch 787/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0902 - accuracy: 0.9667\n",
      "Epoch 788/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0902 - accuracy: 0.9667\n",
      "Epoch 789/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0900 - accuracy: 0.9667\n",
      "Epoch 790/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0899 - accuracy: 0.9667\n",
      "Epoch 791/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0898 - accuracy: 0.9667\n",
      "Epoch 792/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0897 - accuracy: 0.9667\n",
      "Epoch 793/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0895 - accuracy: 0.9667\n",
      "Epoch 794/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0894 - accuracy: 0.9667\n",
      "Epoch 795/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0895 - accuracy: 0.9667\n",
      "Epoch 796/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0892 - accuracy: 0.9667\n",
      "Epoch 797/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0891 - accuracy: 0.9667\n",
      "Epoch 798/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0890 - accuracy: 0.9667\n",
      "Epoch 799/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0889 - accuracy: 0.9667\n",
      "Epoch 800/980\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.0888 - accuracy: 0.9667\n",
      "Epoch 801/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0887 - accuracy: 0.9667\n",
      "Epoch 802/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0886 - accuracy: 0.9667\n",
      "Epoch 803/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0885 - accuracy: 0.9667\n",
      "Epoch 804/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0883 - accuracy: 0.9667\n",
      "Epoch 805/980\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.0882 - accuracy: 0.9667\n",
      "Epoch 806/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0882 - accuracy: 0.9667\n",
      "Epoch 807/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0880 - accuracy: 0.9667\n",
      "Epoch 808/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0879 - accuracy: 0.9667\n",
      "Epoch 809/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0879 - accuracy: 0.9667\n",
      "Epoch 810/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0877 - accuracy: 0.9667\n",
      "Epoch 811/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0876 - accuracy: 0.9667\n",
      "Epoch 812/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0876 - accuracy: 0.9667\n",
      "Epoch 813/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0874 - accuracy: 0.9667\n",
      "Epoch 814/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0874 - accuracy: 0.9667\n",
      "Epoch 815/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0874 - accuracy: 0.9667\n",
      "Epoch 816/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.0871 - accuracy: 0.9667\n",
      "Epoch 817/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0873 - accuracy: 0.9667\n",
      "Epoch 818/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0868 - accuracy: 0.9667\n",
      "Epoch 819/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0867 - accuracy: 0.9667\n",
      "Epoch 820/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0867 - accuracy: 0.9667\n",
      "Epoch 821/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0867 - accuracy: 0.9667\n",
      "Epoch 822/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0864 - accuracy: 0.9667\n",
      "Epoch 823/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0863 - accuracy: 0.9667\n",
      "Epoch 824/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0866 - accuracy: 0.9667\n",
      "Epoch 825/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0863 - accuracy: 0.9667\n",
      "Epoch 826/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0863 - accuracy: 0.9667\n",
      "Epoch 827/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0860 - accuracy: 0.9667\n",
      "Epoch 828/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0860 - accuracy: 0.9667\n",
      "Epoch 829/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0858 - accuracy: 0.9667\n",
      "Epoch 830/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0857 - accuracy: 0.9667\n",
      "Epoch 831/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0856 - accuracy: 0.9667\n",
      "Epoch 832/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0855 - accuracy: 0.9667\n",
      "Epoch 833/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0855 - accuracy: 0.9667\n",
      "Epoch 834/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0853 - accuracy: 0.9667\n",
      "Epoch 835/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0853 - accuracy: 0.9667\n",
      "Epoch 836/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0851 - accuracy: 0.9667\n",
      "Epoch 837/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0851 - accuracy: 0.9667\n",
      "Epoch 838/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0851 - accuracy: 0.9667\n",
      "Epoch 839/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0849 - accuracy: 0.9667\n",
      "Epoch 840/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0849 - accuracy: 0.9667\n",
      "Epoch 841/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0848 - accuracy: 0.9667\n",
      "Epoch 842/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0846 - accuracy: 0.9667\n",
      "Epoch 843/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0845 - accuracy: 0.9667\n",
      "Epoch 844/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0844 - accuracy: 0.9667\n",
      "Epoch 845/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0843 - accuracy: 0.9667\n",
      "Epoch 846/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0843 - accuracy: 0.9667\n",
      "Epoch 847/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0841 - accuracy: 0.9667\n",
      "Epoch 848/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0841 - accuracy: 0.9667\n",
      "Epoch 849/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.0839 - accuracy: 0.9667\n",
      "Epoch 850/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0839 - accuracy: 0.9667\n",
      "Epoch 851/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0839 - accuracy: 0.9667\n",
      "Epoch 852/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0838 - accuracy: 0.9667\n",
      "Epoch 853/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0836 - accuracy: 0.9667\n",
      "Epoch 854/980\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.0834 - accuracy: 0.9667\n",
      "Epoch 855/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.0833 - accuracy: 0.9667\n",
      "Epoch 856/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0834 - accuracy: 0.9667\n",
      "Epoch 857/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0833 - accuracy: 0.9667\n",
      "Epoch 858/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.0831 - accuracy: 0.9667\n",
      "Epoch 859/980\n",
      "150/150 [==============================] - 0s 206us/sample - loss: 0.0830 - accuracy: 0.9667\n",
      "Epoch 860/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0830 - accuracy: 0.9667\n",
      "Epoch 861/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0829 - accuracy: 0.9733\n",
      "Epoch 862/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0830 - accuracy: 0.9667\n",
      "Epoch 863/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0827 - accuracy: 0.9667\n",
      "Epoch 864/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0826 - accuracy: 0.9667\n",
      "Epoch 865/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0824 - accuracy: 0.9667\n",
      "Epoch 866/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0824 - accuracy: 0.9667\n",
      "Epoch 867/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0824 - accuracy: 0.9733\n",
      "Epoch 868/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0823 - accuracy: 0.9733\n",
      "Epoch 869/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0822 - accuracy: 0.9733\n",
      "Epoch 870/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0821 - accuracy: 0.9667\n",
      "Epoch 871/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0819 - accuracy: 0.9667\n",
      "Epoch 872/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0820 - accuracy: 0.9667\n",
      "Epoch 873/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.0818 - accuracy: 0.9667\n",
      "Epoch 874/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0817 - accuracy: 0.9667\n",
      "Epoch 875/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0817 - accuracy: 0.9667\n",
      "Epoch 876/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0816 - accuracy: 0.9667\n",
      "Epoch 877/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0815 - accuracy: 0.9667\n",
      "Epoch 878/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0814 - accuracy: 0.9667\n",
      "Epoch 879/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0813 - accuracy: 0.9667\n",
      "Epoch 880/980\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.0812 - accuracy: 0.9667\n",
      "Epoch 881/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0811 - accuracy: 0.9667\n",
      "Epoch 882/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.96 - 0s 180us/sample - loss: 0.0811 - accuracy: 0.9667\n",
      "Epoch 883/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.0809 - accuracy: 0.9733\n",
      "Epoch 884/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0808 - accuracy: 0.9667\n",
      "Epoch 885/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0808 - accuracy: 0.9667\n",
      "Epoch 886/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0808 - accuracy: 0.9667\n",
      "Epoch 887/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0807 - accuracy: 0.9667\n",
      "Epoch 888/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0806 - accuracy: 0.9667\n",
      "Epoch 889/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0805 - accuracy: 0.9667\n",
      "Epoch 890/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0804 - accuracy: 0.9667\n",
      "Epoch 891/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0803 - accuracy: 0.9667\n",
      "Epoch 892/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0802 - accuracy: 0.9667\n",
      "Epoch 893/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0802 - accuracy: 0.9667\n",
      "Epoch 894/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0801 - accuracy: 0.9667\n",
      "Epoch 895/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1120 - accuracy: 0.96 - 0s 100us/sample - loss: 0.0800 - accuracy: 0.9667\n",
      "Epoch 896/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0799 - accuracy: 0.9667\n",
      "Epoch 897/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0799 - accuracy: 0.9733\n",
      "Epoch 898/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0797 - accuracy: 0.9733\n",
      "Epoch 899/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0796 - accuracy: 0.9667\n",
      "Epoch 900/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0796 - accuracy: 0.9667\n",
      "Epoch 901/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0799 - accuracy: 0.9667\n",
      "Epoch 902/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0794 - accuracy: 0.9667\n",
      "Epoch 903/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0794 - accuracy: 0.9667\n",
      "Epoch 904/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0793 - accuracy: 0.9667\n",
      "Epoch 905/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0794 - accuracy: 0.9667\n",
      "Epoch 906/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0792 - accuracy: 0.9667\n",
      "Epoch 907/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0790 - accuracy: 0.9667\n",
      "Epoch 908/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0791 - accuracy: 0.9667\n",
      "Epoch 909/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0790 - accuracy: 0.9667\n",
      "Epoch 910/980\n",
      "150/150 [==============================] - 0s 180us/sample - loss: 0.0788 - accuracy: 0.9667\n",
      "Epoch 911/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0788 - accuracy: 0.9667\n",
      "Epoch 912/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0788 - accuracy: 0.9667\n",
      "Epoch 913/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0786 - accuracy: 0.9667\n",
      "Epoch 914/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0785 - accuracy: 0.9667\n",
      "Epoch 915/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0786 - accuracy: 0.9667\n",
      "Epoch 916/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0785 - accuracy: 0.9667\n",
      "Epoch 917/980\n",
      "150/150 [==============================] - 0s 179us/sample - loss: 0.0783 - accuracy: 0.9667\n",
      "Epoch 918/980\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.0782 - accuracy: 0.9667\n",
      "Epoch 919/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0783 - accuracy: 0.9667\n",
      "Epoch 920/980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0782 - accuracy: 0.9667\n",
      "Epoch 921/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0781 - accuracy: 0.9667\n",
      "Epoch 922/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0779 - accuracy: 0.9667\n",
      "Epoch 923/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0780 - accuracy: 0.9733\n",
      "Epoch 924/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0777 - accuracy: 0.9667\n",
      "Epoch 925/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0778 - accuracy: 0.9667\n",
      "Epoch 926/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0777 - accuracy: 0.9667\n",
      "Epoch 927/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0776 - accuracy: 0.9667\n",
      "Epoch 928/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0777 - accuracy: 0.9733\n",
      "Epoch 929/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0775 - accuracy: 0.9800\n",
      "Epoch 930/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0774 - accuracy: 0.9800\n",
      "Epoch 931/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0773 - accuracy: 0.9667\n",
      "Epoch 932/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0772 - accuracy: 0.9667\n",
      "Epoch 933/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0773 - accuracy: 0.9667\n",
      "Epoch 934/980\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.0773 - accuracy: 0.9667\n",
      "Epoch 935/980\n",
      "150/150 [==============================] - 0s 173us/sample - loss: 0.0770 - accuracy: 0.9667\n",
      "Epoch 936/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0770 - accuracy: 0.9667\n",
      "Epoch 937/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0768 - accuracy: 0.9800\n",
      "Epoch 938/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0768 - accuracy: 0.9800\n",
      "Epoch 939/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0767 - accuracy: 0.9867\n",
      "Epoch 940/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 1.00 - 0s 126us/sample - loss: 0.0767 - accuracy: 0.9867\n",
      "Epoch 941/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0766 - accuracy: 0.9800\n",
      "Epoch 942/980\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.0765 - accuracy: 0.9800\n",
      "Epoch 943/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.0765 - accuracy: 0.9733\n",
      "Epoch 944/980\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.0764 - accuracy: 0.9667\n",
      "Epoch 945/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0763 - accuracy: 0.9667\n",
      "Epoch 946/980\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.0763 - accuracy: 0.9667\n",
      "Epoch 947/980\n",
      "150/150 [==============================] - 0s 273us/sample - loss: 0.0764 - accuracy: 0.9667\n",
      "Epoch 948/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0763 - accuracy: 0.9667\n",
      "Epoch 949/980\n",
      "150/150 [==============================] - 0s 140us/sample - loss: 0.0761 - accuracy: 0.9800\n",
      "Epoch 950/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0761 - accuracy: 0.9800\n",
      "Epoch 951/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0760 - accuracy: 0.9867\n",
      "Epoch 952/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0759 - accuracy: 0.9800\n",
      "Epoch 953/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0758 - accuracy: 0.9800\n",
      "Epoch 954/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0757 - accuracy: 0.9733\n",
      "Epoch 955/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0759 - accuracy: 0.9800\n",
      "Epoch 956/980\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 0.0756 - accuracy: 0.9800\n",
      "Epoch 957/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.96 - 0s 93us/sample - loss: 0.0755 - accuracy: 0.9667\n",
      "Epoch 958/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0755 - accuracy: 0.9667\n",
      "Epoch 959/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0754 - accuracy: 0.9667\n",
      "Epoch 960/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0753 - accuracy: 0.9667\n",
      "Epoch 961/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0752 - accuracy: 0.9667\n",
      "Epoch 962/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0752 - accuracy: 0.9733\n",
      "Epoch 963/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0752 - accuracy: 0.9867\n",
      "Epoch 964/980\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.0751 - accuracy: 0.9867\n",
      "Epoch 965/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0750 - accuracy: 0.9867\n",
      "Epoch 966/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0750 - accuracy: 0.9867\n",
      "Epoch 967/980\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.0749 - accuracy: 0.9800\n",
      "Epoch 968/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0749 - accuracy: 0.9800\n",
      "Epoch 969/980\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.0748 - accuracy: 0.9867\n",
      "Epoch 970/980\n",
      "150/150 [==============================] - 0s 166us/sample - loss: 0.0747 - accuracy: 0.9867\n",
      "Epoch 971/980\n",
      "150/150 [==============================] - 0s 160us/sample - loss: 0.0747 - accuracy: 0.9867\n",
      "Epoch 972/980\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0746 - accuracy: 0.9867\n",
      "Epoch 973/980\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.0744 - accuracy: 0.9867\n",
      "Epoch 974/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0745 - accuracy: 0.9800\n",
      "Epoch 975/980\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.0743 - accuracy: 0.9667\n",
      "Epoch 976/980\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.0743 - accuracy: 0.9667\n",
      "Epoch 977/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0743 - accuracy: 0.9667\n",
      "Epoch 978/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0742 - accuracy: 0.9667\n",
      "Epoch 979/980\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.0742 - accuracy: 0.9667\n",
      "Epoch 980/980\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.0740 - accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20336609d88>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X,y,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\"sepal_length\":5.1,\n",
    "                 \"sepal_width\":3.5,\n",
    "                 \"petal_length\":1.4,\n",
    "                 \"petal_width\":0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower =scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler,flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE FOR DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "flower_model = load_model('final_iris_model.h5')\n",
    "flower_scaler = joblib.load(\"iris_scaler.pkl\")\n",
    "\n",
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower =scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
